---
title: 'XBOC: Explainable Bag-Of-Concepts'
tags:
  - Python
  - natural language processing
  - document classification
  - document embeddings
  - explainable AI
  - bag-of-concepts
authors:
  - name: Kristiyan Sakalyan
    equal-contrib: true
    affiliation: 1
  - name: Gerhard Johann Hagerer
    equal-contrib: true 
    affiliation: 1
  - name: Ahmed Mosharafa
    equal-contrib: true 
    affiliation: 1
affiliations:
 - name: Technical University of Munich (TUM), Germany
   index: 1
date: 08 April 2024
bibliography: paper.bib
---

# Summary
This paper introduces a novel approach to generating explainable document embeddings. It leverages enhanced Bag-of-Concepts methodology with a focus on transparency, allowing for clear insight into machine learning decision-making processes. This model not only maintains high accuracy and efficiency but also improves interpretability, making it suitable for applications requiring high levels of trust and accountability, such as legal or medical document analysis.

# Statement of Need
Traditional document embedding techniques often yield opaque outputs, limiting their usability in fields requiring transparency. This work addresses the need for explainable AI in natural language processing by providing a framework that enhances the interpretability of document embeddings without compromising performance. Our approach positions itself crucially among existing works like doc2vec, which focus more on performance than on explainability.

# Key References


# Acknowledgements
Special thanks to the contributors and colleagues from the Technical University of Munich (TUM) who provided insights and expertise that greatly assisted the research.
